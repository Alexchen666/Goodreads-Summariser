{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GoodReads Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://rakaarfi.medium.com/scrape-goodreads-book-reviews-using-python-a53252284726"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import polars as pl\n",
    "from langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "Please generate an English summary on the reviews provided by the user. It should mention the postivie aspects, critical feedback, and a balanced conclusion based on the provided information.\n",
    "\n",
    "Specifically, you should include the following points:\n",
    "\n",
    "* The pacing and flow of the story\n",
    "* Character development and memorable personalities\n",
    "* Plot structure and storytelling elements\n",
    "* Any other consistently praised features\n",
    "\n",
    "Please ensure your analysis reflects the frequency and intensity of specific comments rather than just listing individual opinions.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_review(url: str) -> tuple:\n",
    "    \"\"\"\n",
    "    This function scrapes the reviews from a Goodreads book page.\n",
    "    It takes the URL of the book page as input and returns a list of dictionaries,\n",
    "    where each dictionary contains the details of a single review.\n",
    "\n",
    "    Args:\n",
    "    url (str): The URL of the Goodreads book page.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing the title of the book, the author of the book, and a list of dictionaries\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Headers to mimic a real browser request and avoid being blocked\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36'\n",
    "    }\n",
    "    # Send a GET request to fetch the page content\n",
    "    response = requests.get(url, headers=headers)\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = bs(response.content, 'html.parser')\n",
    "\n",
    "    # Extract the book title and author name\n",
    "    title = soup.find('h1', class_='Text Text__title1').get_text()\n",
    "    author = soup.find('span', class_='ContributorLink__name').get_text()\n",
    "\n",
    "    # Find all div tags containing review sections\n",
    "    reviews_list = soup.find_all('div', class_='ReviewsList')\n",
    "\n",
    "    # Select the relevant div that contains the reviews\n",
    "    reviews_tag = reviews_list[1] # Only scrape the second <div>\n",
    "\n",
    "    articles = reviews_tag.find_all('article', class_='ReviewCard')\n",
    "\n",
    "    all_reviews = []\n",
    "\n",
    "    # Loop through each review (article tag) and extract the necessary details\n",
    "    for idx, i in enumerate(articles):\n",
    "        # Extract Reviewer Profile Information\n",
    "        profile_info = i.find('section', class_='ReviewerProfile__info')\n",
    "        \n",
    "        # Extract the reviewer's name and profile link\n",
    "        name = profile_info.find('a').get_text()\n",
    "        link_profile = profile_info.find('a').get('href')\n",
    "        \n",
    "        # Extract the number of books (if available), reviews, and followers and check if the reviewer is an author\n",
    "        profile_meta = profile_info.find('div', class_='ReviewerProfile__meta')\n",
    "        spans = profile_meta.find_all('span')  # Find all span tags inside profile_meta\n",
    "        \n",
    "        # Initialize default values\n",
    "        check_author = False\n",
    "        books_amount = None\n",
    "        reviews_amount = 'Not Found'\n",
    "        followers_amount = 'Not Found'\n",
    "        \n",
    "        for span in spans:\n",
    "            span_text = span.get_text(strip=True)\n",
    "            \n",
    "            # Check if the span contains 'books'\n",
    "            if 'books' in span_text:\n",
    "                books_amount = span_text\n",
    "            \n",
    "            # Check if the span contains 'reviews'\n",
    "            elif 'reviews' in span_text:\n",
    "                reviews_amount = span_text\n",
    "            \n",
    "            # Check if the span contains 'followers'\n",
    "            elif 'followers' in span_text:\n",
    "                followers_amount = span_text\n",
    "            \n",
    "            # Check if the span contains 'Author'\n",
    "            elif 'Author' in span_text:\n",
    "                check_author = span_text\n",
    "\n",
    "        # Store reviewer profile info in a dictionary\n",
    "        profile = {\n",
    "            'Name': name,\n",
    "            'Link Profile': link_profile,\n",
    "            'An Author': bool(check_author), # Will be False if not available\n",
    "            'Books': books_amount,  # Will be None if not available\n",
    "            'Reviews Amount': reviews_amount,  # Will be Not Found if not available\n",
    "            'Followers Amount': followers_amount  # Will be Not Found if not available\n",
    "        }\n",
    "\n",
    "        # Extract the rating (stars) given by the reviewer\n",
    "        shelf_status = i.find('div', class_='ShelfStatus')\n",
    "\n",
    "        # Reviewer can give a rating (stars) or not\n",
    "        try:\n",
    "            rating_given = shelf_status.find('span', class_='RatingStars RatingStars__small').get('aria-label')\n",
    "        except:\n",
    "            rating_given = 'No Rating Given'\n",
    "        # Extract the review content\n",
    "        content = i.find('span', class_='Formatted').get_text(strip=True)\n",
    "        # Create a dictionary with all the extracted data for this review\n",
    "        data = {\n",
    "            'Index': idx + 1,\n",
    "            'Profile Info': profile,\n",
    "            'Rating': rating_given,\n",
    "            'Content': content\n",
    "        }\n",
    "        # Append the review data to the list of all reviews\n",
    "        all_reviews.append(data)\n",
    "\n",
    "    return (title, author, all_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_cleaning(review: list) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    This function creates a Polars DataFrame from the list of dictionaries containing the review data.\n",
    "    Then it cleans the review data by extracting the necessary information from the 'Profile Info' column.\n",
    "    It also converts the 'Reviews Amount' and 'Followers Amount' columns to integers.\n",
    "\n",
    "    Args:\n",
    "    df (pl.DataFrame): A Polars DataFrame containing the review data.\n",
    "\n",
    "    Returns:\n",
    "    pl.DataFrame: A cleaned Polars DataFrame with the necessary information extracted.\n",
    "    \"\"\"\n",
    "    df = pl.DataFrame(review)\n",
    "\n",
    "    df = df.unnest('Profile Info').drop('Link Profile', 'Index', 'Books', 'An Author').with_columns(\n",
    "        pl.col('Reviews Amount').str.replace('reviews', '').str.replace('review', '')\\\n",
    "            .str.replace(' ', '').str.replace(',', '').str.replace('NotFound', '0').cast(pl.Int32).alias('Reviews Amount'),\n",
    "        pl.col('Followers Amount').str.replace(r'(\\d+(?:\\.\\d+)?)[kK]\\s+followers', \n",
    "                                            (pl.col('Followers Amount').str.extract(r'(\\d+(?:\\.\\d+)?)', group_index=1)\\\n",
    "                                                .cast(pl.Float64) * 1000).cast(pl.Int32))\\\n",
    "            .str.replace('followers', '').str.replace('follower', '')\\\n",
    "            .str.replace(' ', '').str.replace(',', '').cast(pl.Int32).alias('Followers Amount'),\n",
    "        pl.col('Rating').str.extract(r'Rating (\\d+) out of').cast(pl.Int32).alias('Rating')\n",
    "        )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_content(df: pl.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    This function extracts the review content from the Polars DataFrame.\n",
    "\n",
    "    Args:\n",
    "    df (pl.DataFrame): A Polars DataFrame containing the review data.\n",
    "\n",
    "    Returns:\n",
    "    str: A string containing the review content.\n",
    "    \"\"\"\n",
    "    \n",
    "    content = df.select(pl.col('Content').str.join('\\n')).to_dicts()\n",
    "    return content[0]['Content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_summarise(content: str, system_prompt: str=system_prompt, model: str='llama3.2:3b') -> str:\n",
    "    \"\"\"\n",
    "    This function generates a summary of the review content using a language model.\n",
    "\n",
    "    Args:\n",
    "    content (str): The review content to be summarised.\n",
    "    system_prompt (str): The system prompt to be used for the summarisation task.\n",
    "    model (str): The name of the language model to be used for summarisation.\n",
    "\n",
    "    Returns:\n",
    "    str: A string containing the summary of the review content.\n",
    "    \"\"\"\n",
    "    llm = ChatOllama(\n",
    "        model = model,\n",
    "        temperature = 0.0\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", content),\n",
    "    ]\n",
    "    ans = llm.invoke(messages).content\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "title, author, review = find_review('PUT YOUR GOODREADS URL HERE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = review_cleaning(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = extract_content(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = llm_summarise(content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
